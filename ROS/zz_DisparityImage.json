{
  "header": {
    "type": "object",
    "properties": {
      "seq": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  Standard metadata for higher-level stamped data types.  This is generally used to communicate timestamped data  in a particular coordinate frame.   sequence ID: consecutively increasing ID "
      },
      "stamp": {
        "type": "string",
        "format": "date-time",
        "description": "Property. Two-integer timestamp that is expressed as:  * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')  * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')  time-handling sugar is provided by the client library "
      },
      "frame_id": {
        "type": "string",
        "description": "Property. Frame this data is associated with "
      }
    }
  },
  "image": {
    "type": "object",
    "properties": {
      "header": {
        "type": "object",
        "properties": {
          "seq": {
            "type": "integer",
            "minimum": 0,
            "description": "Property.  Standard metadata for higher-level stamped data types.  This is generally used to communicate timestamped data  in a particular coordinate frame.   sequence ID: consecutively increasing ID "
          },
          "stamp": {
            "type": "string",
            "format": "date-time",
            "description": "Property. Two-integer timestamp that is expressed as:  * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')  * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')  time-handling sugar is provided by the client library "
          },
          "frame_id": {
            "type": "string",
            "description": "Property. Frame this data is associated with "
          }
        }
      },
      "height": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  Header frame_id should be optical frame of camera  origin of frame should be optical center of camera  +x should point to the right in the image  +y should point down in the image  +z should point into to plane of the image  If the frame_id here and the frame_id of the CameraInfo  message associated with the image conflict  the behavior is undefined  image height, that is, number of rows "
      },
      "width": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  image width, that is, number of columns "
      },
      "encoding": {
        "type": "string",
        "description": "Property.  The legal values for encoding are in file src/image_encodings.cpp  If you want to standardize a new string format, join  ros-users@lists.sourceforge.net and send an email proposing a new encoding.  Encoding of pixels -- channel meaning, ordering, size "
      },
      "is_bigendian": {
        "type": "integer",
        "minimum": 0,
        "maximum": 255,
        "description": "Property.  taken from the list of strings in include/sensor_msgs/image_encodings.h  is this data bigendian? "
      },
      "step": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  Full row length in bytes "
      },
      "data": {
        "type": "array",
        "items": {
          "type": "integer",
          "minimum": 0,
          "maximum": 255
        }
      }
    }
  },
  "f": {
    "type": "number",
    "description": "Property.  Stereo geometry. For disparity d, the depth from the camera is Z = fT/d.  Focal length, pixels "
  },
  "T": {
    "type": "number",
    "description": "Property.  Baseline, world units "
  },
  "valid_window": {
    "type": "object",
    "properties": {
      "x_offset": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  This message is used to specify a region of interest within an image.   When used to specify the ROI setting of the camera when the image was  taken, the height and width fields should either match the height and  width fields for the associated image; or height = width = 0  indicates that the full resolution image was captured.  Leftmost pixel of the ROI "
      },
      "y_offset": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  (0 if the ROI includes the left edge of the image)  Topmost pixel of the ROI "
      },
      "height": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  (0 if the ROI includes the top edge of the image)  Height of ROI "
      },
      "width": {
        "type": "integer",
        "minimum": 0,
        "description": "Property.  Width of ROI "
      },
      "do_rectify": {
        "type": "boolean",
        "description": "Property.  True if a distinct rectified ROI should be calculated from the \"raw\"  ROI in this message. Typically this should be False if the full image  is captured (ROI not used), and True if a subwindow is captured (ROI  used). "
      }
    }
  },
  "min_disparity": {
    "type": "number",
    "description": "Property.  The range of disparities searched.  In the disparity image, any disparity less than min_disparity is invalid.  The disparity search range defines the horopter, or 3D volume that the  stereo algorithm can \"see\". Points with Z outside of:  Z_min = fT / max_disparity  Z_max = fT / min_disparity  could not be found. "
  },
  "max_disparity": {
    "type": "number",
    "description": "Property. "
  },
  "delta_d": {
    "type": "number",
    "description": "Property.  Smallest allowed disparity increment. The smallest achievable depth range  resolution is delta_Z = (Z^2/fT)*delta_d. "
  }
}